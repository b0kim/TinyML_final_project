{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8649c29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /Users/brandon/Library/Python/3.9/lib/python/site-packages (4.46.2)\n",
      "Requirement already satisfied: datasets in /Users/brandon/Library/Python/3.9/lib/python/site-packages (3.1.0)\n",
      "Requirement already satisfied: torch in /Users/brandon/Library/Python/3.9/lib/python/site-packages (2.5.1)\n",
      "Requirement already satisfied: torchvision in /Users/brandon/Library/Python/3.9/lib/python/site-packages (0.20.1)\n",
      "Requirement already satisfied: filelock in /Users/brandon/Library/Python/3.9/lib/python/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /Users/brandon/Library/Python/3.9/lib/python/site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/brandon/Library/Python/3.9/lib/python/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/brandon/Library/Python/3.9/lib/python/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/brandon/Library/Python/3.9/lib/python/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/brandon/Library/Python/3.9/lib/python/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /Users/brandon/Library/Python/3.9/lib/python/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/brandon/Library/Python/3.9/lib/python/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /Users/brandon/Library/Python/3.9/lib/python/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/brandon/Library/Python/3.9/lib/python/site-packages (from transformers) (4.67.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/brandon/Library/Python/3.9/lib/python/site-packages (from datasets) (18.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/brandon/Library/Python/3.9/lib/python/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Users/brandon/Library/Python/3.9/lib/python/site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: xxhash in /Users/brandon/Library/Python/3.9/lib/python/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /Users/brandon/Library/Python/3.9/lib/python/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /Users/brandon/Library/Python/3.9/lib/python/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /Users/brandon/Library/Python/3.9/lib/python/site-packages (from datasets) (3.10.10)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/brandon/Library/Python/3.9/lib/python/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /Users/brandon/Library/Python/3.9/lib/python/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/brandon/Library/Python/3.9/lib/python/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/brandon/Library/Python/3.9/lib/python/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/brandon/Library/Python/3.9/lib/python/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/brandon/Library/Python/3.9/lib/python/site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/brandon/Library/Python/3.9/lib/python/site-packages (from aiohttp->datasets) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/brandon/Library/Python/3.9/lib/python/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/brandon/Library/Python/3.9/lib/python/site-packages (from aiohttp->datasets) (22.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/brandon/Library/Python/3.9/lib/python/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/brandon/Library/Python/3.9/lib/python/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /Users/brandon/Library/Python/3.9/lib/python/site-packages (from aiohttp->datasets) (1.17.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Users/brandon/Library/Python/3.9/lib/python/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/brandon/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/brandon/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/brandon/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/brandon/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/brandon/Library/Python/3.9/lib/python/site-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/brandon/Library/Python/3.9/lib/python/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/brandon/Library/Python/3.9/lib/python/site-packages (from pandas->datasets) (2022.7.1)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.15.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/brandon/Library/Python/3.9/lib/python/site-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers datasets torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0211d82d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['barber chair', 'bookcase', 'china cabinet', 'chiffonier', 'chest', 'cradle', 'desk', 'dining table', 'filing cabinet', 'folding chair', 'four-poster bed', 'infant bed', 'medicine chest', 'rocking chair', 'sofa', 'wardrobe']\n"
     ]
    }
   ],
   "source": [
    "import requests \n",
    "\n",
    "# imagenet labels can be found here\n",
    "labels_url = \"https://raw.githubusercontent.com/anishathalye/imagenet-simple-labels/master/imagenet-simple-labels.json\"\n",
    "imagenet_labels = requests.get(labels_url).json()\n",
    "\n",
    "# domain specific labels of furniture images\n",
    "furniture_labels = [\n",
    "                    \"barber chair\",\n",
    "                    \"bookcase\",\n",
    "                    \"china cabinet\",\n",
    "                    \"chiffonier\",\n",
    "                    \"chest\",\n",
    "                    \"cradle\",\n",
    "                    \"desk\",\n",
    "                    \"dining table\",\n",
    "                    \"filing cabinet\", \n",
    "                    \"folding chair\",\n",
    "                    \"four-poster bed\",\n",
    "                    \"infant bed\",\n",
    "                    \"medicine chest\",\n",
    "                    \"rocking chair\",\n",
    "                    \"sofa\",\n",
    "                    \"wardrobe\"\n",
    "                    ]\n",
    "\n",
    "print(furniture_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ebd390c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2693bc14ce724ea1b01384a25ab3dfad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "from datasets import load_dataset\n",
    "from transformers import ViTForImageClassification, AutoImageProcessor\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "# login to huggingface\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5b20dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = load_dataset(\"imagenet-1k\", split=\"train\", streaming=True)\n",
    "val_ds = load_dataset(\"imagenet-1k\", split=\"validation\", streaming=True)\n",
    "\n",
    "def filter_furniture(example):\n",
    "    return imagenet_labels[example['label']] in furniture_labels\n",
    "\n",
    "furniture_train_ds = train_ds.filter(filter_furniture)\n",
    "furniture_val_ds = val_ds.filter(filter_furniture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b343c2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "765 rocking chair\n",
      "559 folding chair\n",
      "559 folding chair\n",
      "765 rocking chair\n",
      "492 chest\n"
     ]
    }
   ],
   "source": [
    "for sample in furniture_train_ds.take(5):\n",
    "    print(sample['label'], imagenet_labels[sample['label']])\n",
    "    img = sample['image']\n",
    "    img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "decb2d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained ViT model\n",
    "model_name = \"google/vit-base-patch16-224\"\n",
    "model = ViTForImageClassification.from_pretrained(model_name)\n",
    "processor = AutoImageProcessor.from_pretrained(model_name, use_fast=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3c9ff09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Egyptian cat'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test ViT on sample image\n",
    "\n",
    "url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "inputs = processor(images=image, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "logits = outputs.logits\n",
    "# model predicts one of the 1000 ImageNet classes\n",
    "predicted_class_idx = logits.argmax(-1).item()\n",
    "\n",
    "model.config.id2label[predicted_class_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdae50f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rocking chair rocking chair\n",
      "folding chair folding chair\n",
      "folding chair folding chair\n",
      "rocking chair rocking chair\n",
      "chest chest\n",
      "desktop computer desk\n",
      "chiffonier chiffonier\n",
      "cradle cradle\n",
      "window shade dining table\n",
      "medicine chest medicine chest\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get initial accuracy on furniture data\n",
    "\n",
    "num_samples = 0\n",
    "num_correct = 0\n",
    "for sample in furniture_train_ds:\n",
    "    inputs = processor(sample['image'], return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    predicted_class_id = logits.argmax(-1).item()\n",
    "    if predicted_class_id == sample['label']:\n",
    "        num_correct += 1\n",
    "    num_samples += 1\n",
    "\n",
    "    \n",
    "    print(imagenet_labels[predicted_class_id], imagenet_labels[sample['label']])\n",
    "    img = sample['image']\n",
    "    img.show()\n",
    "\n",
    "    if num_samples == 10:\n",
    "        break\n",
    "    \n",
    "\n",
    "accuracy = num_correct / num_samples\n",
    "\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41fa664d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create preprocessing function for batched data\n",
    "def preprocess_images(examples):\n",
    "    # Process images in batch\n",
    "    inputs = processor(examples['image'], return_tensors=\"pt\")\n",
    "    inputs['labels'] = examples['label']\n",
    "    return inputs\n",
    "\n",
    "# Create dataloaders with preprocessing\n",
    "furniture_train_dataloader = DataLoader(\n",
    "    furniture_train_ds.map(preprocess_images, batched=True),\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "\n",
    "furniture_val_dataloader = DataLoader(\n",
    "    furniture_val_ds.map(preprocess_images, batched=True), \n",
    "    batch_size=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4eeeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for finetuning\n",
    "\n",
    "# Set up training parameters\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "num_epochs = 3\n",
    "\n",
    "# # Training loop\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in furniture_train_dataloader:\n",
    "        # Move batch to device\n",
    "        input_ids = batch['pixel_values'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(input_ids, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(furniture_train_dataloader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Average Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c38bd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
